#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
F5-TTS Trained Model Web Interface
–í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ F5-TTS
"""

import os
import sys
import torch
import torchaudio
import gradio as gr
from pathlib import Path
import numpy as np
import tempfile
from datetime import datetime
import soundfile as sf
import json
import shutil

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ ffmpeg –ø—É—Ç–∏ –¥–ª—è Gradio
os.environ['PATH'] = os.environ.get('PATH', '') + ';C:\\ffmpeg\\ffmpeg-master-latest-win64-gpl\\bin'

# –î–µ—Ñ–æ–ª—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
# –û–ü–¢–ò–ú–ê–õ–¨–ù–´–ï –ù–ê–°–¢–†–û–ô–ö–ò –î–õ–Ø –°–¢–ê–ë–ò–õ–¨–ù–û–ô –ì–ï–ù–ï–†–ê–¶–ò–ò
DEFAULT_AUDIO = r"C:\Users\PC\Downloads\F5-TTS\reference_audio_9sec.wav"
DEFAULT_TEXT = "—Ç–≤–æ–∏ –Ω–∞—Å—Ç–æ—è—â–∏–µ –∏ –±—É–¥—É—â–∏–µ. –Ø –º–æ–≥—É –≤—Å–µ —É–∑–Ω–∞—Ç—å - –ø—Ä–æ—à–µ–ø—Ç–∞–ª–∞ –æ–Ω–∞? –í—Å–µ –∏—Å—Ç–æ—Ä–∏–∏, –≤—Å–µ —Å—É–¥—å–±—ã? –ù–æ –Ω–µ —Å–º–æ–∂–µ—à—å –∏–∑–º–µ–Ω–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–π - –∑–∞–º–µ—Ç–∏–ª–∞ –ì–ª–∞—Ñ–∏—Ä–∞. –û–Ω–∏ —É–∂–µ –Ω–∞–ø–∏—Å–∞–Ω—ã. –ó–∞—Ç–æ –Ω–µ –±—É–¥–µ—Ç —Ç—Ä–∞–≥–µ–¥–∏–π. –Ø –±—É–¥—É –∑–Ω–∞—Ç—å."
DEFAULT_REF_TEXT = "—Ç–≤–æ–∏ –Ω–∞—Å—Ç–æ—è—â–∏–µ –∏ –±—É–¥—É—â–∏–µ. –Ø –º–æ–≥—É –≤—Å–µ —É–∑–Ω–∞—Ç—å - –ø—Ä–æ—à–µ–ø—Ç–∞–ª–∞ –æ–Ω–∞? –í—Å–µ –∏—Å—Ç–æ—Ä–∏–∏, –≤—Å–µ —Å—É–¥—å–±—ã?"

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ —á—Ç–µ–Ω–∏—è –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤ —Å –∫–∏—Ä–∏–ª–ª–∏—Ü–µ–π
def safe_audio_load(audio_path):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∞—É–¥–∏–æ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∫–∏—Ä–∏–ª–ª–∏—Ü—ã"""
    try:
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º soundfile (–ª—É—á—à–µ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –ø—É—Ç—è–º–∏)
        audio_data, sample_rate = sf.read(audio_path)
        audio_tensor = torch.from_numpy(audio_data).float()
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
        if len(audio_tensor.shape) == 1:
            audio_tensor = audio_tensor.unsqueeze(0)
        else:
            audio_tensor = audio_tensor.T  # soundfile –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç (samples, channels)
            
        return audio_tensor, sample_rate
    except Exception as e:
        print(f"soundfile failed: {e}, trying torchaudio...")
        try:
            # –ï—Å–ª–∏ soundfile –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –ø—Ä–æ–±—É–µ–º torchaudio
            audio_tensor, sample_rate = torchaudio.load(audio_path)
            return audio_tensor, sample_rate
        except Exception as e2:
            print(f"torchaudio also failed: {e2}")
            raise e2

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ src
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from f5_tts.model import DiT
from f5_tts.infer.utils_infer import (
    load_vocoder,
    load_model,
    preprocess_ref_audio_text,
    infer_process,
    remove_silence_for_generated_wav,
)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –º–æ–¥–µ–ª–∏
model = None
vocoder = None
device = None
sample_rate = 24000
current_model = None

# –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏
MODELS = {
    "base": {
        "name": "–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å F5-TTS",
        "path": "F5-TTS_RUSSIAN_v2_only/F5TTS_v1_Base_v2/model_last.pt",
        "vocab": "F5-TTS_RUSSIAN_v2_only/F5TTS_v1_Base/vocab.txt",
        "description": "–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è –±–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å F5-TTS"
    },
    "trained_200": {
        "name": "–û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å (200 —à–∞–≥–æ–≤)",
        "path": "ckpts/perfect_voice_dataset_final/model_200.pt",
        "vocab": "F5-TTS_RUSSIAN_v2_only/F5TTS_v1_Base/vocab.txt",
        "description": "–†–∞–Ω–Ω—è—è —Å—Ç–∞–¥–∏—è –æ–±—É—á–µ–Ω–∏—è - –º–æ–∂–µ—Ç –±—ã—Ç—å –ª—É—á—à–µ!"
    },
    "trained_400": {
        "name": "–û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å (400 —à–∞–≥–æ–≤)",
        "path": "ckpts/perfect_voice_dataset_final/model_400.pt",
        "vocab": "F5-TTS_RUSSIAN_v2_only/F5TTS_v1_Base/vocab.txt",
        "description": "–°—Ä–µ–¥–Ω—è—è —Å—Ç–∞–¥–∏—è –æ–±—É—á–µ–Ω–∏—è"
    },
    "trained_600": {
        "name": "–û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å (600 —à–∞–≥–æ–≤)",
        "path": "ckpts/perfect_voice_dataset_final/model_600.pt",
        "vocab": "F5-TTS_RUSSIAN_v2_only/F5TTS_v1_Base/vocab.txt",
        "description": "–ü–æ–∑–¥–Ω—è—è —Å—Ç–∞–¥–∏—è –æ–±—É—á–µ–Ω–∏—è"
    },
    "trained_1000": {
        "name": "–û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å (1000 —à–∞–≥–æ–≤)",
        "path": "ckpts/perfect_voice_dataset_final/model_1000.pt",
        "vocab": "F5-TTS_RUSSIAN_v2_only/F5TTS_v1_Base/vocab.txt",
        "description": "–§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å - –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∞!"
    }
}

# –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
os.makedirs("outputs", exist_ok=True)
os.makedirs("generated_audio", exist_ok=True)
os.makedirs("saved_configs", exist_ok=True)
os.makedirs("voices", exist_ok=True)

# Voice Management Functions
def load_saved_voices():
    """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø–∏—Å–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –≥–æ–ª–æ—Å–æ–≤ –∏–∑ voices/"""
    voices = []
    voice_dir = Path("voices")
    if voice_dir.exists():
        for vdir in sorted(voice_dir.iterdir()):
            if vdir.is_dir():
                metadata_file = vdir / "metadata.json"
                if metadata_file.exists():
                    voices.append(vdir.name)
    return voices


def save_voice(voice_name, audio_path, ref_text, trim_start, trim_end):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –≥–æ–ª–æ—Å–∞ —Å –æ–±—Ä–µ–∑–∫–æ–π"""
    if not voice_name or not voice_name.strip():
        return "ERROR –í–≤–µ–¥–∏—Ç–µ –∏–º—è –≥–æ–ª–æ—Å–∞!", gr.update()

    if not audio_path:
        return "ERROR –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∞—É–¥–∏–æ!", gr.update()

    voice_name = voice_name.strip()
    voice_folder = Path("voices") / voice_name
    voice_folder.mkdir(parents=True, exist_ok=True)

    audio_save_path = voice_folder / "audio.wav"
    metadata_path = voice_folder / "metadata.json"

    try:
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∞—É–¥–∏–æ
        audio_data, sr = sf.read(audio_path)

        # –û–±—Ä–µ–∑–∫–∞
        start_sample = int(trim_start * sr)
        end_sample = int(trim_end * sr)

        if end_sample > len(audio_data):
            end_sample = len(audio_data)
        if start_sample >= end_sample:
            return "ERROR –ù–µ–≤–µ—Ä–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω –æ–±—Ä–µ–∑–∫–∏!", gr.update()

        trimmed = audio_data[start_sample:end_sample]

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ WAV
        sf.write(str(audio_save_path), trimmed, sr)

        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        metadata = {
            "ref_text": ref_text,
            "created": datetime.now().isoformat(),
            "sample_rate": sr,
            "duration": len(trimmed) / sr
        }

        with open(metadata_path, "w", encoding="utf-8") as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)

        message = f"OK –ì–æ–ª–æ—Å '{voice_name}' —Å–æ—Ö—Ä–∞–Ω–µ–Ω!"
        print(f"[VOICE] {message}")
        return message, gr.update(choices=load_saved_voices(), value=voice_name)

    except Exception as e:
        return f"ERROR –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}", gr.update()


def load_voice(voice_name):
    """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–≥–æ –≥–æ–ª–æ—Å–∞"""
    if not voice_name:
        return None, ""

    voice_folder = Path("voices") / voice_name
    audio_path = voice_folder / "audio.wav"
    metadata_path = voice_folder / "metadata.json"

    if not audio_path.exists():
        print(f"[VOICE] –ê—É–¥–∏–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {audio_path}")
        return None, ""

    ref_text = ""
    if metadata_path.exists():
        with open(metadata_path, "r", encoding="utf-8") as f:
            metadata = json.load(f)
            ref_text = metadata.get("ref_text", "")

    print(f"[VOICE] –ó–∞–≥—Ä—É–∂–µ–Ω –≥–æ–ª–æ—Å '{voice_name}': {audio_path}")
    print(f"[VOICE] –†–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–π —Ç–µ–∫—Å—Ç: {ref_text[:50]}...")

    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∞–±—Å–æ–ª—é—Ç–Ω—ã–π –ø—É—Ç—å
    return str(audio_path.absolute()), ref_text


def update_trim_slider_max(audio_path):
    """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–∞–∫—Å–∏–º—É–º–∞ —Å–ª–∞–π–¥–µ—Ä–æ–≤ –æ–±—Ä–µ–∑–∫–∏"""
    if not audio_path:
        return gr.update(maximum=30), gr.update(maximum=30, value=10)

    try:
        audio_data, sr = sf.read(audio_path)
        duration = len(audio_data) / sr
        return gr.update(maximum=duration, value=0), gr.update(maximum=duration, value=duration)
    except:
        return gr.update(maximum=30), gr.update(maximum=30, value=10)

def load_model_by_key(model_key="trained"):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –ø–æ –∫–ª—é—á—É"""
    global model, vocoder, device, current_model

    if model_key not in MODELS:
        raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å: {model_key}")

    model_info = MODELS[model_key]

    print("=" * 50)
    print(f"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏: {model_info['name']}")
    print("=" * 50)

    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
    if device is None:
        device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")

        if device == "cuda":
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory // 1024**3
            print(f"GPU: {gpu_name} ({gpu_memory}GB)")

    # –ü—É—Ç–∏ –∫ –º–æ–¥–µ–ª–∏
    model_path = model_info["path"]
    vocab_path = model_info["vocab"]

    if not os.path.exists(model_path):
        raise FileNotFoundError(f"–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {model_path}")

    if not os.path.exists(vocab_path):
        raise FileNotFoundError(f"–°–ª–æ–≤–∞—Ä—å –Ω–µ –Ω–∞–π–¥–µ–Ω: {vocab_path}")

    print(f"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑: {model_path}")
    print(f"–ó–∞–≥—Ä—É–∑–∫–∞ —Å–ª–æ–≤–∞—Ä—è –∏–∑: {vocab_path}")

    # –ó–∞–≥—Ä—É–∑–∫–∞ vocoder (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—â–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω)
    if vocoder is None:
        print("–ó–∞–≥—Ä—É–∑–∫–∞ Vocos vocoder...")
        vocoder = load_vocoder(device=device)

    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    print("–ó–∞–≥—Ä—É–∑–∫–∞ F5-TTS –º–æ–¥–µ–ª–∏...")
    model = load_model(
        model_cls=DiT,
        model_cfg=dict(
            dim=1024,
            depth=22,
            heads=16,
            ff_mult=2,
            text_dim=512,
            conv_layers=4,
        ),
        ckpt_path=model_path,
        vocab_file=vocab_path,
        device=device
    )

    current_model = model_key
    print(f"OK –ú–æ–¥–µ–ª—å {model_info['name']} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
    return model_info["name"]

def load_trained_model():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ (–æ–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å)"""
    return load_model_by_key("base")

def generate_speech(
    text,
    ref_audio,
    ref_text,
    speed=1.0,
    remove_silence=True,
    seed=-1
):
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ—á–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
    """
    global model, vocoder, device
    
    if model is None:
        return None, "ERROR –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!"
    
    try:
        # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
        if seed >= 0:
            torch.manual_seed(seed)
            if torch.cuda.is_available():
                torch.cuda.manual_seed(seed)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        if not text:
            return None, "ERROR –í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞!"
        
        if ref_audio is None:
            return None, "ERROR –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–µ –∞—É–¥–∏–æ!"
        
        # –†–∞–∑—Ä–µ—à–∞–µ–º –ø—É—Å—Ç–æ–π —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–π —Ç–µ–∫—Å—Ç - –ø—É—Å—Ç—å ASR —Å–∞–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç
        if ref_text is None:
            ref_text = ""
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–≥–æ –∞—É–¥–∏–æ
        print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–≥–æ –∞—É–¥–∏–æ: {ref_audio}")
        ref_audio_data, sample_rate_orig = safe_audio_load(ref_audio)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ –º–æ–Ω–æ –µ—Å–ª–∏ —Å—Ç–µ—Ä–µ–æ
        if ref_audio_data.shape[0] > 1:
            ref_audio_data = torch.mean(ref_audio_data, dim=0, keepdim=True)
        
        # –†–µ—Å–µ–º–ø–ª–∏–Ω–≥ –∫ 24kHz –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if sample_rate_orig != sample_rate:
            resampler = torchaudio.transforms.Resample(sample_rate_orig, sample_rate)
            ref_audio_data = resampler(ref_audio_data)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        ref_audio_data = ref_audio_data / torch.max(torch.abs(ref_audio_data))
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–∞  
        ref_audio_processed, ref_text_processed = preprocess_ref_audio_text(
            ref_audio,  # –ü–µ—Ä–µ–¥–∞–µ–º –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É, –∞ –Ω–µ numpy array
            ref_text
        )
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è
        print(f"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ—á–∏: '{text[:50]}...'")
        
        with torch.no_grad():
            generated_audio = infer_process(
                ref_audio_processed,
                ref_text_processed,
                text,
                model,
                vocoder,
                device=device,
                speed=speed
            )
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ (–º–æ–∂–µ—Ç –±—ã—Ç—å tuple —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏)
        if isinstance(generated_audio, (list, tuple)):
            generated_audio = generated_audio[0]  # –ë–µ—Ä–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –∞—É–¥–∏–æ —Å–∏–≥–Ω–∞–ª
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_path = f"outputs/generated_{timestamp}.wav"
        os.makedirs("outputs", exist_ok=True)
        
        sf.write(output_path, generated_audio, sample_rate)
        
        # –£–¥–∞–ª–µ–Ω–∏–µ —Ç–∏—à–∏–Ω—ã –µ—Å–ª–∏ –Ω—É–∂–Ω–æ (—Ñ—É–Ω–∫—Ü–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç —Å —Ñ–∞–π–ª–∞–º–∏)
        if remove_silence:
            remove_silence_for_generated_wav(output_path)  # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ñ–∞–π–ª –Ω–∞–ø—Ä—è–º—É—é
        
        model_name = MODELS.get(current_model, {}).get("name", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å")

        info = f"""
OK **–£—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ!**

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:**
- –ú–æ–¥–µ–ª—å: {model_name}
- –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤
- –°–∫–æ—Ä–æ—Å—Ç—å: {speed}x
- Seed: {seed if seed >= 0 else '—Å–ª—É—á–∞–π–Ω—ã–π'}

**–§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω:** {output_path}
"""
        
        return output_path, info
        
    except Exception as e:
        error_msg = f"ERROR **–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:** {str(e)}"
        print(error_msg)
        return None, error_msg

def save_config(text, ref_text, speed, remove_silence, seed, config_name):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
    if not config_name:
        return "–£–∫–∞–∂–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏!"
    
    config = {
        "text": text,
        "ref_text": ref_text,
        "speed": speed,
        "remove_silence": remove_silence,
        "seed": seed,
        "timestamp": datetime.now().isoformat()
    }
    
    config_path = f"saved_configs/{config_name}.json"
    with open(config_path, 'w', encoding='utf-8') as f:
        json.dump(config, f, ensure_ascii=False, indent=2)
    
    return f"OK –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {config_path}"

def load_config(config_name):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
    if not config_name:
        return None, None, 1.0, True, -1, "–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é!"
    
    config_path = f"saved_configs/{config_name}.json"
    if not os.path.exists(config_path):
        return None, None, 1.0, True, -1, f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {config_path}"
    
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        return (
            config.get("text", ""),
            config.get("ref_text", ""),
            config.get("speed", 1.0),
            config.get("remove_silence", True),
            config.get("seed", -1),
            f"OK –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {config_name}"
        )
    except Exception as e:
        return None, None, 1.0, True, -1, f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}"

def get_saved_configs():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π"""
    config_dir = Path("saved_configs")
    if not config_dir.exists():
        return []
    
    configs = []
    for config_file in config_dir.glob("*.json"):
        configs.append(config_file.stem)
    
    return sorted(configs)

def copy_to_outputs(audio_path):
    """–ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ –≤ –ø–∞–ø–∫—É –≤—ã–≤–æ–¥–∞"""
    if not audio_path:
        return "–ù–µ—Ç –∞—É–¥–∏–æ –¥–ª—è –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è!"

    try:
        filename = os.path.basename(audio_path)
        dest_path = f"generated_audio/{filename}"
        shutil.copy2(audio_path, dest_path)
        return f"OK –§–∞–π–ª —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω: {dest_path}"
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è: {e}"

def switch_model(model_key):
    """–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
    try:
        model_name = load_model_by_key(model_key)
        description = MODELS[model_key]["description"]
        return description, f"OK –ú–æ–¥–µ–ª—å –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∞ –Ω–∞: {model_name}"
    except Exception as e:
        return f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}", f"‚ùå –û—à–∏–±–∫–∞: {e}"

def create_interface():
    """–°–æ–∑–¥–∞–Ω–∏–µ Gradio –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞"""

    # CSS –¥–ª—è –∫—Ä–∞—Å–Ω–æ–π –∫–Ω–æ–ø–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    custom_css = """
    .generate-button {
        background: linear-gradient(to right, #8B0000, #DC143C) !important;
        border: none !important;
        color: white !important;
        font-weight: bold !important;
        font-size: 18px !important;
        box-shadow: 0 4px 6px rgba(139, 0, 0, 0.3) !important;
    }
    .generate-button:hover {
        background: linear-gradient(to right, #A52A2A, #FF4444) !important;
        box-shadow: 0 6px 8px rgba(139, 0, 0, 0.4) !important;
        transform: translateY(-2px);
        transition: all 0.3s ease;
    }
    .generate-button:active {
        transform: translateY(0px);
        box-shadow: 0 2px 4px rgba(139, 0, 0, 0.3) !important;
    }
    """

    with gr.Blocks(title="F5-TTS Trained Model", theme=gr.themes.Soft(), css=custom_css) as interface:
        gr.Markdown("""
        # F5-TTS Trained Model Interface
        
        **–í–∞—à–∞ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å F5-TTS**
        - –û–±—É—á–µ–Ω–∞ –Ω–∞ 5.6 —á–∞—Å–∞—Ö –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ
        - 15 —ç–ø–æ—Ö —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ –Ω–∞ RTX 3090
        - 2519 —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å —Ç–æ—á–Ω–æ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–µ–π
        """)
        
        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("### üìù –í—Ö–æ–¥–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã")

                # –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ –≥–æ–ª–æ—Å–æ–≤
                with gr.Accordion("üé§ –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ –≥–æ–ª–æ—Å–æ–≤", open=True):
                    with gr.Row():
                        voice_dropdown = gr.Dropdown(
                            label="–°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –≥–æ–ª–æ—Å–∞",
                            choices=load_saved_voices(),
                            value=None,
                            interactive=True,
                            scale=3
                        )
                        load_voice_btn = gr.Button("–ó–∞–≥—Ä—É–∑–∏—Ç—å", variant="secondary", scale=1)
                        refresh_voices_btn = gr.Button("–û–±–Ω–æ–≤–∏—Ç—å", scale=1)

                    with gr.Accordion("üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –Ω–æ–≤—ã–π –≥–æ–ª–æ—Å", open=False):
                        voice_name_input = gr.Textbox(
                            label="–ò–º—è –≥–æ–ª–æ—Å–∞",
                            placeholder="–í–≤–µ–¥–∏—Ç–µ –∏–º—è –¥–ª—è –≥–æ–ª–æ—Å–∞"
                        )
                        voice_audio_input = gr.Audio(
                            label="–ê—É–¥–∏–æ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è",
                            type="filepath"
                        )
                        with gr.Row():
                            trim_start = gr.Slider(0, 30, 0, label="–ù–∞—á–∞–ª–æ (—Å–µ–∫)", step=0.1)
                            trim_end = gr.Slider(0, 30, 10, label="–ö–æ–Ω–µ—Ü (—Å–µ–∫)", step=0.1)
                        voice_ref_text_input = gr.Textbox(
                            label="–¢–µ–∫—Å—Ç –æ–±—Ä–∞–∑—Ü–∞",
                            lines=2,
                            placeholder="–¢–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–æ–∏–∑–Ω–æ—Å–∏—Ç—Å—è –≤ –∞—É–¥–∏–æ"
                        )
                        save_voice_btn = gr.Button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≥–æ–ª–æ—Å", variant="primary")
                        save_voice_status = gr.Textbox(
                            label="–°—Ç–∞—Ç—É—Å",
                            interactive=False,
                            show_label=False
                        )

                # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
                model_dropdown = gr.Dropdown(
                    label="–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å",
                    choices=[(info["name"], key) for key, info in MODELS.items()],
                    value="base",
                    interactive=True
                )

                # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
                model_info = gr.Markdown(
                    value=MODELS["base"]["description"],
                    elem_id="model_info"
                )

                # –°—Ç–∞—Ç—É—Å —Å–º–µ–Ω—ã –º–æ–¥–µ–ª–∏
                model_status = gr.Textbox(
                    label="–°—Ç–∞—Ç—É—Å –º–æ–¥–µ–ª–∏",
                    value="–ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é",
                    interactive=False
                )

                # –¢–µ–∫—Å—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
                text_input = gr.Textbox(
                    label="–¢–µ–∫—Å—Ç –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞",
                    placeholder="–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ...",
                    lines=3,
                    value=DEFAULT_TEXT
                )
                
                # –†–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–µ –∞—É–¥–∏–æ
                ref_audio_input = gr.Audio(
                    label="–†–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–µ –∞—É–¥–∏–æ (–≤–∞—à –≥–æ–ª–æ—Å)",
                    type="filepath",
                    elem_id="ref_audio",
                    value=DEFAULT_AUDIO if os.path.exists(DEFAULT_AUDIO) else None
                )
                
                # –¢–µ–∫—Å—Ç —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–∞
                ref_text_input = gr.Textbox(
                    label="–¢–µ–∫—Å—Ç —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–≥–æ –∞—É–¥–∏–æ",
                    placeholder="–í–≤–µ–¥–∏—Ç–µ —Ç–æ—á–Ω—ã–π —Ç–µ–∫—Å—Ç —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–≥–æ –∞—É–¥–∏–æ...",
                    lines=2,
                    value=DEFAULT_REF_TEXT
                )
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
                with gr.Accordion("‚öôÔ∏è –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏", open=False):
                    speed_slider = gr.Slider(
                        minimum=0.5,
                        maximum=2.0,
                        value=1.0,
                        step=0.1,
                        label="–°–∫–æ—Ä–æ—Å—Ç—å —Ä–µ—á–∏"
                    )
                    
                    remove_silence_checkbox = gr.Checkbox(
                        value=True,
                        label="–£–¥–∞–ª–∏—Ç—å —Ç–∏—à–∏–Ω—É –≤ –Ω–∞—á–∞–ª–µ/–∫–æ–Ω—Ü–µ"
                    )
                    
                    seed_input = gr.Number(
                        value=-1,
                        label="Seed (–¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏, -1 = —Å–ª—É—á–∞–π–Ω—ã–π)",
                        precision=0
                    )
                
                # –ö–Ω–æ–ø–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
                generate_btn = gr.Button(
                    "–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–µ—á—å",
                    variant="primary",
                    size="lg",
                    elem_classes="generate-button"
                )
                
                # –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è–º–∏
                with gr.Accordion("–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫", open=False):
                    config_name_input = gr.Textbox(
                        label="–ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏",
                        placeholder="–ú–æ—è_–∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è"
                    )
                    
                    with gr.Row():
                        save_config_btn = gr.Button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏", variant="secondary")
                        load_config_btn = gr.Button("–ó–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏", variant="secondary")
                    
                    config_dropdown = gr.Dropdown(
                        label="–í—ã–±–µ—Ä–∏—Ç–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é",
                        choices=get_saved_configs(),
                        interactive=True
                    )
                    
                    config_status = gr.Textbox(
                        label="–°—Ç–∞—Ç—É—Å",
                        interactive=False
                    )
            
            with gr.Column(scale=1):
                gr.Markdown("### –†–µ–∑—É–ª—å—Ç–∞—Ç")
                
                # –í—ã—Ö–æ–¥–Ω–æ–µ –∞—É–¥–∏–æ
                output_audio = gr.Audio(
                    label="–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∞—É–¥–∏–æ",
                    type="filepath",
                    elem_id="output_audio"
                )
                
                # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
                output_info = gr.Markdown(
                    value="*–ó–¥–µ—Å—å –ø–æ—è–≤–∏—Ç—Å—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏...*"
                )
                
                # –ö–Ω–æ–ø–∫–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ñ–∞–π–ª–∞–º–∏
                with gr.Row():
                    copy_btn = gr.Button("–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –≤ generated_audio", variant="secondary")
                    
                file_status = gr.Textbox(
                    label="–°—Ç–∞—Ç—É—Å —Ñ–∞–π–ª–∞",
                    interactive=False
                )
        
        # –ü—Ä–∏–º–µ—Ä—ã
        gr.Markdown("### üí° –ü—Ä–∏–º–µ—Ä—ã —Ç–µ–∫—Å—Ç–æ–≤")
        gr.Examples(
            examples=[
                ["–î–æ–±—Ä—ã–π –¥–µ–Ω—å! –ú–µ–Ω—è –∑–æ–≤—É—Ç –ê–ª–µ–∫—Å–∞–Ω–¥—Ä, –∏ —è —Ä–∞–¥ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –≤–∞—Å."],
                ["–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ —Ä–∞–∑–≤–∏–≤–∞—é—Ç—Å—è —Å –Ω–µ–≤–µ—Ä–æ—è—Ç–Ω–æ–π —Å–∫–æ—Ä–æ—Å—Ç—å—é."],
                ["–°–µ–≥–æ–¥–Ω—è –ø—Ä–µ–∫—Ä–∞—Å–Ω–∞—è –ø–æ–≥–æ–¥–∞ –¥–ª—è –ø—Ä–æ–≥—É–ª–∫–∏ –≤ –ø–∞—Ä–∫–µ."],
                [DEFAULT_TEXT],
                ["–≠—Ç–æ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏."],
            ],
            inputs=text_input
        )
        
        # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        generate_btn.click(
            fn=generate_speech,
            inputs=[
                text_input,
                ref_audio_input,
                ref_text_input,
                speed_slider,
                remove_silence_checkbox,
                seed_input
            ],
            outputs=[output_audio, output_info],
            show_progress=True
        )
        
        # –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π
        save_config_btn.click(
            fn=save_config,
            inputs=[
                text_input,
                ref_text_input,
                speed_slider,
                remove_silence_checkbox,
                seed_input,
                config_name_input
            ],
            outputs=config_status
        ).then(
            fn=lambda: gr.update(choices=get_saved_configs()),
            outputs=config_dropdown
        )

        load_config_btn.click(
            fn=load_config,
            inputs=[config_dropdown],
            outputs=[
                text_input,
                ref_text_input,
                speed_slider,
                remove_silence_checkbox,
                seed_input,
                config_status
            ]
        )

        # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞
        copy_btn.click(
            fn=copy_to_outputs,
            inputs=[output_audio],
            outputs=[file_status]
        )

        # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–º–µ–Ω—ã –º–æ–¥–µ–ª–∏
        model_dropdown.change(
            fn=switch_model,
            inputs=[model_dropdown],
            outputs=[model_info, model_status],
            show_progress=True
        )

        # –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≥–æ–ª–æ—Å–∞–º–∏
        load_voice_btn.click(
            fn=load_voice,
            inputs=[voice_dropdown],
            outputs=[ref_audio_input, ref_text_input]
        )

        refresh_voices_btn.click(
            fn=lambda: gr.update(choices=load_saved_voices()),
            outputs=[voice_dropdown]
        )

        voice_audio_input.upload(
            fn=update_trim_slider_max,
            inputs=[voice_audio_input],
            outputs=[trim_start, trim_end]
        )

        save_voice_btn.click(
            fn=save_voice,
            inputs=[voice_name_input, voice_audio_input, voice_ref_text_input, trim_start, trim_end],
            outputs=[save_voice_status, voice_dropdown]
        )

        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –≤–Ω–∏–∑—É
        gr.Markdown("""
        ---
        ### –°–æ–≤–µ—Ç—ã –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞:
        
        1. **–†–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–µ –∞—É–¥–∏–æ:** –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —á–∏—Å—Ç—É—é –∑–∞–ø–∏—Å—å –≤–∞—à–µ–≥–æ –≥–æ–ª–æ—Å–∞ (3-10 —Å–µ–∫—É–Ω–¥)
        2. **–¢–µ–∫—Å—Ç —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–∞:** –£–∫–∞–∂–∏—Ç–µ —Ç–æ—á–Ω—ã–π —Ç–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–æ–∏–∑–Ω–æ—Å–∏—Ç—Å—è –≤ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–µ
        3. **–ü—É–Ω–∫—Ç—É–∞—Ü–∏—è:** –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∑–∞–ø—è—Ç—ã–µ –∏ —Ç–æ—á–∫–∏ –¥–ª—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø–∞—É–∑
        4. **–°–∫–æ—Ä–æ—Å—Ç—å:** –ù–∞—á–Ω–∏—Ç–µ —Å 1.0, –∑–∞—Ç–µ–º –ø–æ–¥—Å—Ç—Ä–æ–π—Ç–µ –ø–æ–¥ –≤–∞—à–∏ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è
        5. **–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ:** –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ "–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏" –¥–ª—è –∑–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π
        6. **–ê—Ä—Ö–∏–≤:** –ö–æ–ø–∏—Ä—É–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ generated_audio/ –¥–ª—è –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–≥–æ —Ö—Ä–∞–Ω–µ–Ω–∏—è
        
        **–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞:**
        - –í—ã–±–æ—Ä –º–µ–∂–¥—É –æ–±—É—á–µ–Ω–Ω–æ–π –∏ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª—å—é F5-TTS
        - –ê–≤—Ç–æ–∑–∞–≥—Ä—É–∑–∫–∞ –¥–µ—Ñ–æ–ª—Ç–Ω–æ–≥–æ –∞—É–¥–∏–æ –∏ —Ç–µ–∫—Å—Ç–∞
        - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ—Å–µ—Ç–æ–≤ –Ω–∞—Å—Ç—Ä–æ–µ–∫
        - –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ –ø–æ—Å—Ç–æ—è–Ω–Ω—É—é –ø–∞–ø–∫—É
        - –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏ –ø—Ä–∏–º–µ—Ä—ã —Ç–µ–∫—Å—Ç–æ–≤

        **–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:**
        - **–û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å:** –ü–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–∞ –≤–∞—à–µ–º –≥–æ–ª–æ—Å–µ (5.6—á, 15 —ç–ø–æ—Ö)
        - **–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å:** –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è F5-TTS –º–æ–¥–µ–ª—å –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        
        **GPU —Å—Ç–∞—Ç—É—Å:** """ + (
            f"OK CUDA –¥–æ—Å—Ç—É–ø–Ω–∞ ({torch.cuda.get_device_name(0)})" 
            if torch.cuda.is_available() 
            else "WARNING CPU —Ä–µ–∂–∏–º (–º–µ–¥–ª–µ–Ω–Ω–µ–µ)"
        ) + f"""
        
        **–ú–æ–¥–µ–ª—å:** –û–±—É—á–µ–Ω–∞ –Ω–∞ 5.6—á –∞—É–¥–∏–æ, 15 —ç–ø–æ—Ö, 2519 —Å–µ–≥–º–µ–Ω—Ç–æ–≤  
        **–ü–∞–ø–∫–∏:** outputs/ (–≤—Ä–µ–º–µ–Ω–Ω—ã–µ), generated_audio/ (–ø–æ—Å—Ç–æ—è–Ω–Ω—ã–µ), saved_configs/ (–Ω–∞—Å—Ç—Ä–æ–π–∫–∏)
        """)
    
    return interface

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("=" * 60)
    print("F5-TTS TRAINED MODEL WEB INTERFACE")
    print("=" * 60)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    try:
        load_trained_model()
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
        return
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–ø—É—Å–∫ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
    interface = create_interface()
    
    print("\n" + "=" * 60)
    print("–ó–∞–ø—É—Å–∫ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞...")
    print("=" * 60)
    
    interface.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        inbrowser=True
    )

if __name__ == "__main__":
    main()